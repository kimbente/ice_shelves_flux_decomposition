{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make torch.dataset ###\n",
    "# takes two separate tensors as input\n",
    "dataset = TensorDataset(data[:, :2], data[:, 2:])\n",
    "\n",
    "# Inspect\n",
    "# Shape of (first) X sample\n",
    "print(dataset[0][0].shape)\n",
    "# Shape of (first) Y sample\n",
    "print(dataset[0][1].shape)\n",
    "\n",
    "### Define sizes n observations for splits ###\n",
    "train_size = int(0.7 * dataset.__len__())\n",
    "test_size = dataset.__len__() - train_size\n",
    "print(f\"Train size: {train_size}, Test size: {test_size}\")\n",
    "\n",
    "### Random split ###\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "### Create DataLoaders ###\n",
    "train_loader = DataLoader(train_dataset, batch_size = 1024, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1024, shuffle = False)\n",
    "all_loader = DataLoader(dataset, batch_size = 1024, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8976f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Training loop -----\n",
    "if RETRAIN:\n",
    "    model = HelmholtzResNN().to(device)\n",
    "    # 5e-3 was a bit jittery\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr = 1e-3, weight_decay = 1e-7)\n",
    "    loss_function = nn.MSELoss()\n",
    "\n",
    "    # epochs = 10\n",
    "    epochs = 30\n",
    "    # print every N batches\n",
    "    # print_every = 500\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses  = []\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        # ------------------ TRAIN ------------------\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        \n",
    "        # NOTE: Here on train only\n",
    "        for i, (X_batch, Y_batch) in enumerate(train_loader):\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "\n",
    "            optim.zero_grad(set_to_none = True)\n",
    "            Y_hat = model(X_batch)\n",
    "            loss = loss_function(Y_hat, Y_batch)\n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optim.step()\n",
    "\n",
    "            train_loss_sum += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_avg_train_loss = train_loss_sum / len(train_loader.dataset)\n",
    "\n",
    "        # ------------------ EVAL ------------------\n",
    "        model.eval()\n",
    "        test_loss_sum = 0.0\n",
    "\n",
    "        for i, (X_batch, Y_batch) in enumerate(test_loader):\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "\n",
    "            # need requires_grad for autograd in model\n",
    "            X_batch_grad = X_batch.clone().detach().requires_grad_(True)\n",
    "\n",
    "            Y_hat = model(X_batch_grad)\n",
    "            loss = loss_function(Y_hat, Y_batch)\n",
    "            test_loss_sum += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_avg_test_loss = test_loss_sum / len(test_loader.dataset)\n",
    "\n",
    "        # store for plotting later\n",
    "        train_losses.append(epoch_avg_train_loss)\n",
    "        test_losses.append(epoch_avg_test_loss)\n",
    "\n",
    "        # Print only every epoch: ~ 1.5 min per epoch\n",
    "        # ~14 min for 10 epochs on GPU\n",
    "        print(f\"[epoch {ep:03d}] train_loss = {epoch_avg_train_loss:.6f} | test_loss = {epoch_avg_test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d21543",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    torch.save(model.state_dict(), \"trained_model/helmholtz_resnn.pth\")\n",
    "    pd.DataFrame({'train_loss': train_losses, 'test_loss': test_losses}).to_csv(\"trained_model/helmholtz_resnn_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9761ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    # Assume you already have train_losses and test_losses lists\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.plot(epochs, train_losses, label = \"Train Loss\", marker = \"o\")\n",
    "    plt.plot(epochs, test_losses, label = \"Test Loss\", marker = \"s\")\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Test Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.grid(True, linestyle = \"--\", alpha = 0.6)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
